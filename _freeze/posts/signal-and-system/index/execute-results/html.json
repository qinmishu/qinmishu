{
  "hash": "177bec8b840a37034aa6239209caa894",
  "result": {
    "markdown": "---\ntitle: Signal and System a Primer\nauthor: 秦米书\ndate: '2023-09-10'\ncategories:\n  - telecom\nimage: image.jpg\nformat:\n  html:\n    toc: true\neditor: visual\n---\n\nThis is a note for Signal and System a Primer with Matlab. I don't have Matlab, but I may use Scilab/Octave/Python/Julia/R/Haskell instead when necessary.\n\n# reference\n\n[latex cheetsheet](https://quickref.me/latex)\n\n[mermaid](https://mermaid.js.org/syntax/flowchart.html) \n\n[greeksymbols](https://www.greeksymbols.net/) \n\n[julia plots](https://docs.juliaplots.org/latest/tutorial/)\n\n[quarto](https://quarto.org/)\n\n# 1 Basic Concepts\n\nSignal: x(t), function of time, simplified definition.\n\nSystem: A collection of devices that operate on input signal x(t) and produce output signal y(t).\n\nContinuous time signal: takes a value at every instant of time.\n\nDiscrete time signal: is only defined at particular instant of time.\n\nPeriodic vs nonperiodic signals\n\nAnalog vs digital signals\n\nADC: Analog to Digital Converter\n\nFor continuous signal x(t), the normalized energy E of x(t) is (assuming x(t) is real)\n\n$$\nE = \\int_{-\\infty}^{+\\infty} x(t)^2 dt \n$$\n\nThe normalized power P is\n\n$$\nP = \\lim\\limits_{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T/2}^{+T/2} x(t)^2 dt \n$$\n\nIf x(t) is complex valued\n\n$$\nE = \\int_{-\\infty}^{+\\infty} \\vert x(t) \\vert ^2 dt \n$$\n\nThe normalized power P is\n\n$$\nP = \\lim\\limits_{T \\rightarrow \\infty} \\frac{1}{T} \\int_{-T/2}^{+T/2} \\vert x(t) \\vert ^2 dt \n$$\n\nFor discrete time signal x\\[n\\]\n\n$$\nE = \\sum_{n = -\\infty}^{+\\infty} \\vert x[n] \\vert ^2 \n$$\n\nThe normalized power P\n\n$$\nP = \\lim\\limits_{N \\rightarrow \\infty} \\frac{1}{2N+1} \\sum_{n = -N}^{+N} \\vert x[n] \\vert ^2 \n$$\n\nEnergy signal: $0<E<\\infty$\n\nPower signal: $0<P<\\infty$\n\nEven vs Odd signal\n\nAny signal can be represented as sum of even and odd signals\n\n$$ \n\\begin{align}\nx(t) = x_e(t) + x_o(t) \\\\\nx_e(t) = \\frac{1}{2} ( x(t) + x(-t) ) \\\\\nx_o(t) = \\frac{1}{2} ( x(t) - x(-t) ) \n\\end{align}\n$$\n\n## 1.4 basic continuous time signals\n\nUnit step function u(t)\n\n$$\nu(t) = \\begin{cases}\n   1 &\\text{t > 0} \\\\\n   0 &\\text{t < 0}   \n\\end{cases}\n$$\n\nUnit impulse function $\\delta(t)$\n\n$$\n\\delta(t) = \\frac{d}{dt}u(t) = \\begin{cases}\n   0 & t \\ne 0 \\\\\n   \\text{undefined} & t = 0 \n\\end{cases}\n$$\n\nThe impulse function has the property(called sampling or sifting property)\n\n$$\n\\int_{a}^{b} f(t) \\delta(t-t_0)  dt = \\int_{a}^{b} f(t_0) \\delta(t-t_0) dt = f(t_0) \\int_{a}^{b} \\delta(t-t_0) dt = f(t_0) \n$$\n\nUnit ramp function\n\n$$\nr(t) = t \\times u(t)\n$$\n\nUnit rectangle pulse function\n\nUnit triangular pulse function\n\nsinusoidal signal\n\nexponential signal\n\n## 1.5 basic discrete time signals\n\nUnit step sequence\n\n$$\nu(n) = \\begin{cases}\n   0 &\\text{n < 0} \\\\\n   1 & n \\ge 0 \n\\end{cases}\n$$\n\nUnit impulse sequence\n\n$$\n\\delta(n) = \\begin{cases}\n   0 & n \\ne 0 \\\\\n   1 & n = 0 \n\\end{cases}\n$$\n\nUnit ramp sequence\n\n$$\nr(n) = \\begin{cases}\n   0 & n < 0 \\\\\n   n & n \\ge 0 \n\\end{cases}\n$$\n\nSinusoidal sequence\n\nExponential sequence\n\n## 1.6 Basic operations on signals\n\nTime reversal\n\nTime scaling\n\nTime shifting\n\nAmplitude transformation\n\n## 1.7 Classifications of systems\n\ncontinuous time vs discrete time systems\n\ncausal vs noncausal systems: A causal system is one whose output y(t) at present time depends only on the present and past values(not future) of the input x(t).\n\nlinear and nonlinear systems: Linearity is the property of the system describing a linear relationship between input (cause) and output (effect). The property is a combination of both homogeneity(scaling) property and the additivity property. The homogeneity property requires that if the input is multiplied by any constant k, then the output is multiplied by the same constant. The additivity property requires that the response to a sum of inputs is the sum of the responses to each input applied separately.\n\n$$ \nT \\lbrace k_1 x_1 + k_2 x_2 \\rbrace = k_1 y_1 + k_2 y_2 \n$$\n\ntime varying and time invariant systems: A time-varying system is one whose parameters vary with time. In a time-invariant system, a time shift (advance or delay) in the input signal leads to the time shift in the output signal.\n\nsystems with and without memory: When the output of a system depends on the past and/or future input, the system is said to have a memory. A memoryless system is one in which the current output depends only on the current input; it does not depend on the past or future inputs.A system with a memory is also called a dynamic system. A memoryless system is called a static system.\n\n# 2 Convolution\n\nThe behavior of the system can be described mathematically either in the time domain or in the frequency domain.\n\nConvolution is a tool for time-domain analysis of systems.\n\nLTI system: Linear, time-invariant system\n\n## 2.2 Impulse response \n\nThe impulse response h(t) is the response of the system when the input is the unit impulse function $\\delta(t)$, that is,\n\n$$\nh(t) = T \\delta(t)\n$$\n\nThe input signal x(t) can be expressed as ($\\tau$ is a dummy variable) the below equation. It is the sifting property of the unit impulse.\n\n$$\nx(t) = \\int_{-\\infty}^{+\\infty} x(\\tau) \\delta(t-\\tau)d\\tau   \n$$\n\nThe response y(t) to the input x(t) is obtained by:\n\n$$\n\\begin{align}\ny(t) &= Tx(t)=T \\lbrace \\int_{-\\infty}^{+\\infty} x(\\tau) \\delta(t-\\tau)d\\tau \\rbrace \\\\\n&= \\int_{-\\infty}^{+\\infty} x(\\tau) T \\lbrace \\delta(t-\\tau) \\rbrace d\\tau \\\\\n&= \\int_{-\\infty}^{+\\infty} x(\\tau)  h(t-\\tau)  d\\tau\n\\end{align}\n$$\n\nThis shows that an LTI system is characterized by its impulse response.\n\n## 2.3 Convolution Integral \n\nThe below equation is also called convolution integral or superposition integral. \n\n$$\ny(t) = \\int_{-\\infty}^{+\\infty} x(\\tau)  h(t-\\tau)  d\\tau\n$$\n\nThe convolution of two signals x(t) and h(t) is usually written in terms of the operator `*`. That is, y(t) equals x(t) convolved with h(t). \n\n$$\ny(t) = x(t) * h(t) = \\int_{-\\infty}^{+\\infty} x(\\tau)  h(t-\\tau)  d\\tau\n$$\n\nWe can split the integral into two parts: \n\n$$\ny(t) = x(t) * h(t) = \\int_{-\\infty}^{t_0} x(\\tau)  h(t-\\tau)  d\\tau + \\int_{t_0}^{+\\infty} x(\\tau)  h(t-\\tau)  d\\tau\n$$\n\nThe 1st part is $y_{zir}$, the 2nd part is $y_{zsr}$. \n\nZIR: Zero Input Response. (natural response) \n\nZSR: Zero State Response. (the forced response)\n\n$t_0$ is the initial time. \n\nThe convolution integral can be simplified if we assume that a system has two properties. \n\nFirst, if x(t) = 0 for t < 0, then \n\n$$\ny(t) = x(t) * h(t) = \\int_{-\\infty}^{+\\infty} x(\\tau) h(t-\\tau)  d\\tau = \\int_{0}^{+\\infty} x(\\tau) h(t-\\tau)  d\\tau\n$$ \n\nSecond, if we assume that the system is causal (that is y(t) does not depend on future signal of x(t) or h(t)), h(t) = 0 for t < 0, the equation becomes, \n\n$$\ny(t) = x(t) * h(t) = \\int_{-\\infty}^{+\\infty} x(\\tau) h(t-\\tau)  d\\tau = \\int_{0}^{t} x(\\tau) h(t-\\tau)  d\\tau\n$$ \n\nImportant properties of the convolution integral: \n\n(1) The order in which two functions are convolved is unmportant. \n\n(2) Width property. If the durations of x(t) and h(t) are $T_1$ and $T_2$, then the duration of $y(t) = x(t) * h(t)$ is $T_1 + T_2$. If the areas under x(t) and h(t) are $A_1$ and $A_2$, then the area under $y(t) = x(t) * h(t)$ is $A_1A_2$. \n\nThe convolution integral can be evaluated in 3 different ways: \n\n1. Analytical method, which involves performing the integration by hand when x(t) and h(t) are specified analytically.  \n2. Graphical method, which is appropriate when x(t) and h(t) are provided in graphical form.  \n3. Numerical method, where we approximate x(t) and h(t) by numerical sequence and obtain y(t) by discrete convolution using a digital computer. \n\n\n\n## 2.4 Graphical convolution \n\nGraphical method of evaluating the convolution integral. This method usually involves 4 steps: \n\n1. Folding: Take the mirror image of $h(\\tau)$ about the ordinate(vertical) axis\n2. Shifting: Displace or shift $h(\\tau)$ by t to obtain $h(t-\\tau)$ \n3. Multiplication: Multiply $h(t-\\tau)$ and $x(\\tau)$ together \n4. Integration: For a given t, integrate the product $h(t-\\tau)x(\\tau)$ over $0 < \\tau < t$ to get y(t) at t \n\nWe are going to use the below auxiliary functions.  \n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nfunction step(t)\n    if t >= 0  \n        return 1 \n    else \n        return 0 \n    end \nend \n\nfunction ramp(t)\n    return t*step(t)\nend \n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\nramp (generic function with 1 method)\n```\n:::\n:::\n\n\nObtain the convolution of the two signals in @fig-graph-convolution-ex-1\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\nusing Plots\nusing LaTeXStrings \n\nx(t) = step(t) \n\nh(t) = ramp(t+2) * step(-t) + 2*step(t)*step(2-t)\n\nxplot = plot(x,-2,2,title=\"x(t)\")\nhplot = plot(h,-2,2,title=\"h(t)\")\nplot(xplot,hplot,layout=(1,2), legend=false)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n![graph convolution example](index_files/figure-html/fig-graph-convolution-ex-1-output-1.svg){#fig-graph-convolution-ex-1}\n:::\n:::\n\n\nDefinition of x(t)\n$$\nx(t) = step(t) \n$$\n\nDefinition of h(t) \n$$\nh(t) = \\begin{cases}\n   2+t &\\text{-2 < t < 0} \\\\\n   1 &\\text{0 < t < 2}   \n\\end{cases}\n$$ \n\nIn this case, it is easy to fold x(t), the unit step function. Let \n\n$$ \ny(t) = x(t)*h(t) = \\int x(t-\\tau)h(\\tau)d\\tau\n$$\n\nFirst, we fold x(t) \n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nx_fold(t) = x(-t)\n\nplot(x_fold, -2, 2, title=L\"x(- \\tau)\", legend=false)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n![](index_files/figure-html/cell-4-output-1.svg){}\n:::\n:::\n\n\nand shift it by t \n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\nt = 1\n\nx_shift(tau) = x(t-tau)\n\nplot(x_shift, -3, 2, title=L\"x(t - \\tau)\", legend=false)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n![](index_files/figure-html/cell-5-output-1.svg){}\n:::\n:::\n\n\nFor $t < -2$, there is no overlap of the two signals, as shown in @fig-graph-convolution-ex-1-less-minus-2 , Hence, \n\n$$\ny(t) = x(t) * h(t) = 0, t< -2 \n$$\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\nt = -2.5 \n\nplot(x_shift,-3,2,label=L\"x(t - \\tau)\")\nplot!(h,-3,2,label=L\"h(\\tau)\")\ntitle!( \"convolution x(t)*h(t), t < -2\")\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n![t < -2](index_files/figure-html/fig-graph-convolution-ex-1-less-minus-2-output-1.svg){#fig-graph-convolution-ex-1-less-minus-2}\n:::\n:::\n\n\nFor -2 < t < 0, the two signals overlap between -2 and t, as shown in figure @fig-graph-convolution-ex-1-minus-2-and-0 , Hence, \n\n$$\n\\begin{align}\ny(t) &= \\int_{-2}^{t} x(t-\\tau)h(\\tau)d\\tau \\\\\n&= \\int_{-2}^{t} (1)(2+\\tau) d\\tau \\\\\n&= 2\\tau + \\frac{\\tau^2}{2} \\biggr\\rvert_{-2}^{t} = 0.5 t^2 + 2t + 2, \\text{-2 < t < 0} \n\\end{align}\n$$\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\nt = -1.5 \n\nplot(x_shift,-3,2,label=L\"x(t - \\tau)\")\nplot!(h,-3,2,label=L\"h(\\tau)\")\ntitle!( \"convolution x(t)*h(t), -2 < t < 0\")\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n![-2 < t < 0](index_files/figure-html/fig-graph-convolution-ex-1-minus-2-and-0-output-1.svg){#fig-graph-convolution-ex-1-minus-2-and-0}\n:::\n:::\n\n\nFor 0 < t < 2, the two signals overlap between -2 and t, as shown in figure @fig-graph-convolution-ex-1-0-and-2 , Hence, \n\n$$\n\\begin{align}\ny(t) &= \\int_{-2}^{t} x(t-\\tau)h(\\tau)d\\tau \\\\\n&= \\int_{-2}^{0} (1)(2+\\tau) d\\tau + \\int_{0}^{t}(1)(2) d\\tau \\\\\n&= (2 \\tau + \\frac{\\tau^2}{2}) \\biggr\\rvert_{-2}^{0} + 2 \\tau \\biggr\\rvert_{0}^{t} \\\\\n&= 2+2t , \\text{0 < t < 2} \n\\end{align}\n$$\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code}\nt = 1 \n\nplot(x_shift,-3,2,label=L\"x(t - \\tau)\")\nplot!(h,-3,3,label=L\"h(\\tau)\")\ntitle!( \"convolution x(t)*h(t), 0 < t < 2\")\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n![0 < t < 2](index_files/figure-html/fig-graph-convolution-ex-1-0-and-2-output-1.svg){#fig-graph-convolution-ex-1-0-and-2}\n:::\n:::\n\n\nFor  t > 2, the two signals overlap between -2 and 2, as shown in figure @fig-graph-convolution-ex-1-gt-2 , Hence, \n\n$$\n\\begin{align}\ny(t) &= \\int_{-2}^{t} x(t-\\tau)h(\\tau)d\\tau \\\\\n&= \\int_{-2}^{0} (1)(2+\\tau) d\\tau + \\int_{0}^{2}(2)(2) d\\tau \\\\\n&= (2 \\tau + \\frac{\\tau^2}{2}) \\biggr\\rvert_{-2}^{0} + 2 \\tau \\biggr\\rvert_{0}^{2} \\\\\n&= 6 , \\text{ t > 2} \n\\end{align}\n$$\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\nt = 2.5\n\nplot(x_shift,-3,3,label=L\"x(t - \\tau)\")\nplot!(h,-3,3,label=L\"h(\\tau)\")\ntitle!( \"convolution x(t)*h(t), t > 2\")\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n![t > 2](index_files/figure-html/fig-graph-convolution-ex-1-gt-2-output-1.svg){#fig-graph-convolution-ex-1-gt-2}\n:::\n:::\n\n\nCombining the results, we obtain, see  @fig-graph-convolution-ex-1-result\n\n$$\ny(t) = \\begin{cases}\n   0.5t^2 + 2t + 2,  &\\text{-2 < t < 0} \\\\\n   2t+2,  &\\text{0 < t < 2} \\\\\n   6, &\\text{ t > 2} \\\\\n   0, &\\text{otherwise} \n\\end{cases}\n$$ \n\n::: {.cell execution_count=9}\n``` {.julia .cell-code}\ny(t) = begin \n   if (-2 <= t) && (t <= 0)\n      0.5*t*t + 2*t + 2 \n   elseif (0 <= t) && (t <= 2)\n      2*t + 2 \n   elseif t > 2 \n      6 \n   else\n      0  \n   end    \nend \n\nplot(y,-4,4)\ntitle!( \"convolution x(t)*h(t), result\")\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n![convolution result](index_files/figure-html/fig-graph-convolution-ex-1-result-output-1.svg){#fig-graph-convolution-ex-1-result}\n:::\n:::\n\n\n## 2.5 Block Diagram Representation of continuous signal convolution properties \n\nThe commutative property of the convolution integral. \n\n```{mermaid}\nflowchart LR \nsubgraph g1[1]\n    direction LR    \n    x[\"x(t)\" ]-->h[\"h(t)\" ]-->y[\"y(t)\"];\n    style x stroke-width:0px\n    style y stroke-width:0px\nend \n\nsubgraph g2[2]\n    direction LR \n    h1[\"h(t)\" ]-->x1[\"x(t)\" ]-->y1[\"y(t)\"];\n    style h1 stroke-width:0px\n    style y1 stroke-width:0px\nend \n\ng1-.-|equals|g2\n```\n\n\n\nThe associative property of the convolution integral. \n\n```{mermaid}\nflowchart LR \nsubgraph g1[1]\n    direction LR    \n    x[\"x(t)\" ]-->h1[\"h1(t)\" ]-->h2[\"h2(t)\" ]-->y[\"y(t)\"];\n    style x stroke-width:0px\n    style y stroke-width:0px\nend \n\nsubgraph g2[2]\n    direction LR \n    xx[\"x(t)\" ]-->convolution[\"h1(t)*h2(t)\" ]-->yy[\"y(t)\"];\n    style xx stroke-width:0px\n    style yy stroke-width:0px\nend \n\ng1-.-|equals|g2\n```\n\n\n\nThe distributive property of the convolution integral. \n\n```{mermaid}\nflowchart LR \nsubgraph g1[1]\n    direction LR    \n    x[\"x(t)\"]-->h1[\"h1(t)\"] & h2[\"h2(t)\"] \n    h1-->y[\"y(t)\"] \n    h2-->y \n    style x stroke-width:0px\n    style y stroke-width:0px\nend \n\nsubgraph g2[2]\n    direction LR \n    xx[\"x(t)\" ]-->addition[\"h1(t)+h2(t)\" ]-->yy[\"y(t)\"];\n    style xx stroke-width:0px\n    style yy stroke-width:0px\nend \n\ng1-.-|equals|g2\n```\n\n\n## 2.6 Discrete Convolution \n\nUnit step sequence definition \n\n$$\nu[n] = \\begin{cases}\n   0 \\ n < 0 \\\\\n   1 \\ n \\ge 0 \n\\end{cases}\n$$\n\nUnit impulse sequence definition \n\n$$ \n\\delta(n) = \\begin{cases} \n    0 \\ n \\ne 0 \\\\\n    1 \\ n = 0 \n\\end{cases}\n$$ \n\nAn alternative way of expressing any discrete signal x[n]. I.e. we can represent x[n] as a weighted sum of delayed impulses. \n\n$$\nx[n] = \\sum_{k=-\\infty}^{\\infty} x[k] \\delta[n-k]\n$$ \n\nThe multiplication property of the impulse function is (The 2 equations hold because $\\delta[n] = 1$ only if n is 0 )\n\n$$ \n\\begin{align}\n\\delta[n] x[n-k] &= x[-k] \\delta[n] \\\\ \n\\delta[n-k] x[n] &= x[k] \\delta[n-k] \n\\end{align}\n$$ \n\nThe impulse response h[n] of of a discrete LTI system is the response of the system when the input is $\\delta[n]$. I.e. \n\n$$ \nh[n] = T\\{\\delta[n]\\}\n$$ \n\nor \n\n\n```{mermaid} \nflowchart LR \n      \n    delta[\"δ[n]\" ]-->s[\"system T\" ]-->h[\"h[n]\"];\n    style delta stroke-width:0px\n    style h stroke-width:0px\n```\n\n\nThe convolution of the discrete input signal x[n] and impulse response h[n] is (`*` is the convolution symbol)\n\n$$ \ny[n] = x[n] * h[n]\n$$\n\nIt is defined as \n\n$$ \ny[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h[n-k] \n$$ \n\nThis is known as the **convolution sum** or **superposition sum** for the system response. \n\nAs in continuous time convolution, one of the signals is time-inverted, shifted and then multiplied by the other. By the change of variables $m=n-k$, we have (m in the below equation, and k in the above equation are called dummy variables)\n\n$$\ny[n] = \\sum_{m=-\\infty}^{\\infty} x[n-m] h[m]\n$$ \n\nThis shows the order of summation is immaterial; discrete convolution is commutative. \n\nProperties of convolution sum. \n\n$$ \n\\begin{align}\n& x[n]*h[n] = h[n]*x[n] \\quad \\text{commutative} \\\\\n& f[n]*[x[n]+y[n]] = f[n]*x[n] + f[n]*y[n] \\quad \\text{distributative} \\\\\n& f[n]*[x[n]*y[n]] = [f[n]*x[n]]*y[n] \\quad \\text{associative} \\\\\n& x[n-m]*h[n-k] = y[n-m-k] \\quad \\text{shifting} \\\\\n& x[n]*\\delta[n] = x[n] \n\\end{align}\n$$ \n\nIf both x[n] and h[n] are causal, that is, x[n] and h[n] are 0 for all $ n < 0 $, the summation becomes \n\n$$\ny[n] = \\sum_{m=0}^{n} x[n-m] h[m]\n$$ \n\nThe convolution of M-point sequence with a N-point sequence produces an (M+N-1)-point sequence. \n\nEvaluating the convolution sum requires the following steps:  \n\n\n1.\tThe signal h[k] is time-reversed to get h[−k] and then shifted by n to form h[n − k] or h[−(k − n)], which should be regarded as a function of k with parameter n.\n2.\tFor a fixed value of n, multiply x[k] and h[n − k] for all values of k.\n3.\tThe product x[k]h[n − k] is summed over all k to produce a single value of y[n].\n4.\tRepeat steps 1–3 for various values of n to produce the entire output y[n].\n\nExample, find r[n], given that r[n] is the convolution of 2 unit step sequences, that is \n\n$$\nr[n] = u[n] * u[n]\n$$\n\nSolution: \n\n$$\nr[n] = u[n] * u[n] = \\sum_{k=-\\infty}^{\\infty} u[k] u[n-k] \n$$ \n\nThe function u[k], u[-k], u[n-k] are shown in in@fig-discrete-convolution-ex . The convolution takes place when we multiply the sequences (a) with (c) and (d).\n\nFor $n<0$, the non-zero values of u[k] and u[n-k] do not overlap, so $u[k] u[n-k] = 0$ for all values of k. This implies that $r[n] = 0$ for $n < 0$. \n\nFor $n \\ge 0$, he non-zero values of u[k] and u[n-k] overlap. This overlap begins with u[k] at k = 0 and ends with u[n-k] at k = n. Hence,\n\n$$\nr[n] = \\sum_{k=0}^n u[k]u[n-k] = \\sum_{k=0}^n (1) = n + 1 \n$$\n\nTherefore (considering both $n<0$ and $n \\ge 0$), $r[n] = (n+1)u[n]$. This is the unit ramp sequence and is shown in (e). \n\n::: {.cell execution_count=10}\n``` {.julia .cell-code}\nusing Plots\n\nu(k)=begin\n    if k >= 0 \n        1\n    else \n        0 \n    end \nend \n\nn = -3 \nxs = collect(-10:10)\ny_u_k = u.(xs) \ny_minus_u_k =  u.(xs*(-1)) \n\n#n < 0 \ny_n_minus_k = u.((xs .- n)*(-1))\n\nu_k = plot(xs,y_u_k,seriestype=:sticks,markershape=:circle, ylimit=[0,2],legend=false,title=\"u(k) --- (a)\") \n\nu_minus_k = plot(xs,y_minus_u_k,seriestype=:sticks,markershape=:circle, ylimit=[0,2],legend=false,title=\"u(-k) --- (b)\") \n\nu_n_minus_k = plot(xs,y_n_minus_k,seriestype=:sticks,markershape=:circle, ylimit=[0,2],legend=false,title=\"u(n-k) n<0 --- (c)\") \n\nn = 3 \n# n > 0 \ny_n_minus_k = u.((xs .- n)*(-1))\nu_n_minus_k_n_gt_0 = plot(xs,y_n_minus_k,seriestype=:sticks,markershape=:circle, ylimit=[0,2],legend=false,title=\"u(n-k) n>=0 --- (d)\") \n\nr(k) = u(k)*(k+1)\nr_sequence = r.(xs) \nr_n = plot(xs,r_sequence,seriestype=:sticks,markershape=:circle, ylimit=[0,12],legend=false,title=\"r(n) --- (e)\") \n\nplot(u_k,u_minus_k,u_n_minus_k,u_n_minus_k_n_gt_0,r_n,layout=(3,2))\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n![discrete convolution example](index_files/figure-html/fig-discrete-convolution-ex-output-1.svg){#fig-discrete-convolution-ex}\n:::\n:::\n\n\n## 2.7 Block diagram of discrete convolution properties \n\n\nThe commutative property \n\n```{mermaid}\nflowchart LR \nsubgraph g1[1]\n    direction LR    \n    x[\"x[n]\" ]-->h[\"h[n]\" ]-->y[\"y[n]\"];\n    style x stroke-width:0px\n    style y stroke-width:0px\nend \n\nsubgraph g2[2]\n    direction LR \n    h1[\"h[n]\" ]-->x1[\"x[n]\" ]-->y1[\"y[n]\"];\n    style h1 stroke-width:0px\n    style y1 stroke-width:0px\nend \n\ng1-.-|equals|g2\n```\n\n\n\nThe associative property \n\n```{mermaid}\nflowchart LR \nsubgraph g1[1]\n    direction LR    \n    x[\"x[n]\" ]-->h1[\"h1[n]\" ]-->h2[\"h2[n]\" ]-->y[\"y[n]\"];\n    style x stroke-width:0px\n    style y stroke-width:0px\nend \n\nsubgraph g2[2]\n    direction LR \n    xx[\"x[n]\" ]-->convolution[\"h1[n]*h2[n]\" ]-->yy[\"y[n]\"];\n    style xx stroke-width:0px\n    style yy stroke-width:0px\nend \n\ng1-.-|equals|g2\n```\n\n\n\nThe distributive property \n\n```{mermaid}\nflowchart LR \nsubgraph g1[1]\n    direction LR    \n    x[\"x[n]\"]-->h1[\"h1[n]\"] & h2[\"h2[n]\"] \n    h1-->y[\"y(t)\"] \n    h2-->y \n    style x stroke-width:0px\n    style y stroke-width:0px\nend \n\nsubgraph g2[2]\n    direction LR \n    xx[\"x[n]\" ]-->addition[\"h1[n]+h2[n]\" ]-->yy[\"y[n]\"];\n    style xx stroke-width:0px\n    style yy stroke-width:0px\nend \n\ng1-.-|equals|g2\n```\n\n\n## 2.8 Deconvolution \n\nWe know that if the impulse response h[n] of a system is known, we can find the response y[n] to an input x[n] as simply the convolution of x[n] and h[n]. If we know x[n] and y[n], how do we get h[n]? The process of getting h[n], given x[n] and y[n], is known as deconvolution. The process is also known as inverse filtering or system identification. \n\nDeconvolution has no direct mathematical definition in the continuous-time domain. Discrete convolution can be done in 2 ways: poly-nomial division and recursive algorithm. \n\n# The Laplace Transform \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}