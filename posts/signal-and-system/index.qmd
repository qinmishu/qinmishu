---
title: "Signal and System a Primer"
author: "秦米书"
date: "2023-09-10"
categories: [telecom]
image: "image.jpg"
format: 
  html:
    toc: true 
editor: visual
jupyter: julia-1.8
---

This is a note for Signal and System a Primer with Matlab. I don't have Matlab, but I may use Scilab/Octave/Python/Julia/R/Haskell instead when necessary.

# reference

[latex cheetsheet](https://quickref.me/latex)

[mermaid](https://mermaid.js.org/syntax/flowchart.html) 

# 1 Basic Concepts

Signal: x(t), function of time, simplified definition.

System: A collection of devices that operate on input signal x(t) and produce output signal y(t).

Continuous time signal: takes a value at every instant of time.

Discrete time signal: is only defined at particular instant of time.

Periodic vs nonperiodic signals

Analog vs digital signals

ADC: Analog to Digital Converter

For continuous signal x(t), the normalized energy E of x(t) is (assuming x(t) is real)

$$
E = \int_{-\infty}^{+\infty} x(t)^2 dt 
$$

The normalized power P is

$$
P = \lim\limits_{T \rightarrow \infty} \frac{1}{T} \int_{-T/2}^{+T/2} x(t)^2 dt 
$$

If x(t) is complex valued

$$
E = \int_{-\infty}^{+\infty} \vert x(t) \vert ^2 dt 
$$

The normalized power P is

$$
P = \lim\limits_{T \rightarrow \infty} \frac{1}{T} \int_{-T/2}^{+T/2} \vert x(t) \vert ^2 dt 
$$

For discrete time signal x\[n\]

$$
E = \sum_{n = -\infty}^{+\infty} \vert x[n] \vert ^2 
$$

The normalized power P

$$
P = \lim\limits_{N \rightarrow \infty} \frac{1}{2N+1} \sum_{n = -N}^{+N} \vert x[n] \vert ^2 
$$

Energy signal: $0<E<\infty$

Power signal: $0<P<\infty$

Even vs Odd signal

Any signal can be represented as sum of even and odd signals

$$ 
\begin{align}
x(t) = x_e(t) + x_o(t) \\
x_e(t) = \frac{1}{2} ( x(t) + x(-t) ) \\
x_o(t) = \frac{1}{2} ( x(t) - x(-t) ) 
\end{align}
$$

## 1.4 basic continuous time signals

Unit step function u(t)

$$
u(t) = \begin{cases}
   1 &\text{t > 0} \\
   0 &\text{t < 0}   
\end{cases}
$$

Unit impulse function $\delta(t)$

$$
\delta(t) = \frac{d}{dt}u(t) = \begin{cases}
   0 & t \ne 0 \\
   \text{undefined} & t = 0 
\end{cases}
$$

The impulse function has the property(called sampling or sifting property)

$$
\int_{a}^{b} f(t) \delta(t-t_0)  dt = \int_{a}^{b} f(t_0) \delta(t-t_0) dt = f(t_0) \int_{a}^{b} \delta(t-t_0) dt = f(t_0) 
$$

Unit ramp function

$$
r(t) = t \times u(t)
$$

Unit rectangle pulse function

Unit triangular pulse function

sinusoidal signal

exponential signal

## 1.5 basic discrete time signals

Unit step sequence

$$
u(n) = \begin{cases}
   0 &\text{n < 0} \\
   1 & n \ge 0 
\end{cases}
$$

Unit impulse sequence

$$
\delta(n) = \begin{cases}
   0 & n \ne 0 \\
   1 & n = 0 
\end{cases}
$$

Unit ramp sequence

$$
r(n) = \begin{cases}
   0 & n < 0 \\
   n & n \ge 0 
\end{cases}
$$

Sinusoidal sequence

Exponential sequence

## 1.6 Basic operations on signals

Time reversal

Time scaling

Time shifting

Amplitude transformation

## 1.7 Classifications of systems

continuous time vs discrete time systems

causal vs noncausal systems: A causal system is one whose output y(t) at present time depends only on the present and past values(not future) of the input x(t).

linear and nonlinear systems: Linearity is the property of the system describing a linear relationship between input (cause) and output (effect). The property is a combination of both homogeneity(scaling) property and the additivity property. The homogeneity property requires that if the input is multiplied by any constant k, then the output is multiplied by the same constant. The additivity property requires that the response to a sum of inputs is the sum of the responses to each input applied separately.

$$ 
T \lbrace k_1 x_1 + k_2 x_2 \rbrace = k_1 y_1 + k_2 y_2 
$$

time varying and time invariant systems: A time-varying system is one whose parameters vary with time. In a time-invariant system, a time shift (advance or delay) in the input signal leads to the time shift in the output signal.

systems with and without memory: When the output of a system depends on the past and/or future input, the system is said to have a memory. A memoryless system is one in which the current output depends only on the current input; it does not depend on the past or future inputs.A system with a memory is also called a dynamic system. A memoryless system is called a static system.

# 2 Convolution

The behavior of the system can be described mathematically either in the time domain or in the frequency domain.

Convolution is a tool for time-domain analysis of systems.

LTI system: Linear, time-invariant system

## 2.2 Impulse response 

The impulse response h(t) is the response of the system when the input is the unit impulse function $\delta(t)$, that is,

$$
h(t) = T \delta(t)
$$

The input signal x(t) can be expressed as ($\tau$ is a dummy variable) the below equation. It is the sifting property of the unit impulse.

$$
x(t) = \int_{-\infty}^{+\infty} x(\tau) \delta(t-\tau)d\tau   
$$

The response y(t) to the input x(t) is obtained by:

$$
\begin{align}
y(t) &= Tx(t)=T \lbrace \int_{-\infty}^{+\infty} x(\tau) \delta(t-\tau)d\tau \rbrace \\
&= \int_{-\infty}^{+\infty} x(\tau) T \lbrace \delta(t-\tau) \rbrace d\tau \\
&= \int_{-\infty}^{+\infty} x(\tau)  h(t-\tau)  d\tau
\end{align}
$$

This shows that an LTI system is characterized by its impulse response.

## 2.3 Convolution Integral 

The below equation is also called convolution integral or superposition integral. 

$$
y(t) = \int_{-\infty}^{+\infty} x(\tau)  h(t-\tau)  d\tau
$$

The convolution of two signals x(t) and h(t) is usually written in terms of the operator `*`. That is, y(t) equals x(t) convolved with h(t). 

$$
y(t) = x(t) * h(t) = \int_{-\infty}^{+\infty} x(\tau)  h(t-\tau)  d\tau
$$

We can split the integral into two parts: 

$$
y(t) = x(t) * h(t) = \int_{-\infty}^{t_0} x(\tau)  h(t-\tau)  d\tau + \int_{t_0}^{+\infty} x(\tau)  h(t-\tau)  d\tau
$$

The 1st part is $y_{zir}$, the 2nd part is $y_{zsr}$. 

ZIR: Zero Input Response. (natural response) 

ZSR: Zero State Response. (the forced response)

$t_0$ is the initial time. 

The convolution integral can be simplified if we assume that a system has two properties. 

First, if x(t) = 0 for t < 0, then 

$$
y(t) = x(t) * h(t) = \int_{-\infty}^{+\infty} x(\tau) h(t-\tau)  d\tau = \int_{0}^{+\infty} x(\tau) h(t-\tau)  d\tau
$$ 

Second, if we assume that the system is causal (that is y(t) does not depend on future signal of x(t) or h(t)), h(t) = 0 for t < 0, the equation becomes, 

$$
y(t) = x(t) * h(t) = \int_{-\infty}^{+\infty} x(\tau) h(t-\tau)  d\tau = \int_{0}^{t} x(\tau) h(t-\tau)  d\tau
$$ 

Important properties of the convolution integral: 

(1) The order in which two functions are convolved is unmportant. 

(2) Width property. If the durations of x(t) and h(t) are $T_1$ and $T_2$, then the duration of $y(t) = x(t) * h(t)$ is $T_1 + T_2$. If the areas under x(t) and h(t) are $A_1$ and $A_2$, then the area under $y(t) = x(t) * h(t)$ is $A_1A_2$. 

The convolution integral can be evaluated in 3 different ways: 

1. Analytical method, which involves performing the integration by hand when x(t) and h(t) are specified analytically.  
2. Graphical method, which is appropriate when x(t) and h(t) are provided in graphical form.  
3. Numerical method, where we approximate x(t) and h(t) by numerical sequence and obtain y(t) by discrete convolution using a digital computer. 



## 2.4 Graphical convolution 

Graphical method of evaluating the convolution integral. This method usually involves 4 steps: 

1. Folding: Take the mirror image of $h(\tau)$ about the ordinate(vertical) axis
2. Shifting: Displace or shift $h(\tau)$ by t to obtain $h(t-\tau)$ 
3. Multiplication: Multiply $h(t-\tau)$ and $x(\tau)$ together 
4. Integration: For a given t, integrate the product $h(t-\tau)x(\tau)$ over $0 < \tau < t$ to get y(t) at t 

We are going to use the below auxiliary functions.  
```{julia}
function step(t)
    if t >= 0  
        return 1 
    else 
        return 0 
    end 
end 

function ramp(t)
    return t*step(t)
end 
```

Obtain the convolution of the two signals in @fig-graph-convolution-ex-1

```{julia}
#| label: fig-graph-convolution-ex-1
#| fig-cap: "graph convolution example"
using Plots
using LaTeXStrings 

x(t) = step(t) 

h(t) = ramp(t+2) * step(-t) + 2*step(t)*step(2-t)

xplot = plot(x,-2,2,title="x(t)")
hplot = plot(h,-2,2,title="h(t)")
plot(xplot,hplot,layout=(1,2), legend=false)
```

Definition of x(t)
$$
x(t) = step(t) 
$$

Definition of h(t) 
$$
h(t) = \begin{cases}
   2+t &\text{-2 < t < 0} \\
   1 &\text{0 < t < 2}   
\end{cases}
$$ 

In this case, it is easy to fold x(t), the unit step function. Let 

$$ 
y(t) = x(t)*h(t) = \int x(t-\tau)h(\tau)d\tau
$$

First, we fold x(t) 

```{julia}
x_fold(t) = x(-t)

plot(x_fold, -2, 2, title=L"x(- \tau)", legend=false)
```

and shift it by t 

```{julia}
t = 1

x_shift(tau) = x(t-tau)

plot(x_shift, -3, 2, title=L"x(t - \tau)", legend=false)
```

For $t < -2$, there is no overlap of the two signals, as shown in @fig-graph-convolution-ex-1-less-minus-2 , Hence, 

$$
y(t) = x(t) * h(t) = 0, t< -2 
$$

```{julia}
#| label: fig-graph-convolution-ex-1-less-minus-2
#| fig-cap: t < -2 
t = -2.5 

plot(x_shift,-3,2,label=L"x(t - \tau)")
plot!(h,-3,2,label=L"h(\tau)")
title!( "convolution x(t)*h(t), t < -2")
```

For -2 < t < 0, the two signals overlap between -2 and t, as shown in figure @fig-graph-convolution-ex-1-minus-2-and-0 , Hence, 

$$
\begin{align}
y(t) &= \int_{-2}^{t} x(t-\tau)h(\tau)d\tau \\
&= \int_{-2}^{t} (1)(2+\tau) d\tau \\
&= 2\tau + \frac{\tau^2}{2} \biggr\rvert_{-2}^{t} = 0.5 t^2 + 2t + 2, \text{-2 < t < 0} 
\end{align}
$$

```{julia}
#| label: fig-graph-convolution-ex-1-minus-2-and-0
#| fig-cap:  -2 < t < 0
t = -1.5 

plot(x_shift,-3,2,label=L"x(t - \tau)")
plot!(h,-3,2,label=L"h(\tau)")
title!( "convolution x(t)*h(t), -2 < t < 0")
```

For 0 < t < 2, the two signals overlap between -2 and t, as shown in figure @fig-graph-convolution-ex-1-0-and-2 , Hence, 

$$
\begin{align}
y(t) &= \int_{-2}^{t} x(t-\tau)h(\tau)d\tau \\
&= \int_{-2}^{0} (1)(2+\tau) d\tau + \int_{0}^{t}(1)(2) d\tau \\
&= (2 \tau + \frac{\tau^2}{2}) \biggr\rvert_{-2}^{0} + 2 \tau \biggr\rvert_{0}^{t} \\
&= 2+2t , \text{0 < t < 2} 
\end{align}
$$

```{julia}
#| label: fig-graph-convolution-ex-1-0-and-2
#| fig-cap:  0 < t < 2
t = 1 

plot(x_shift,-3,2,label=L"x(t - \tau)")
plot!(h,-3,3,label=L"h(\tau)")
title!( "convolution x(t)*h(t), 0 < t < 2")
```


For  t > 2, the two signals overlap between -2 and 2, as shown in figure @fig-graph-convolution-ex-1-gt-2 , Hence, 

$$
\begin{align}
y(t) &= \int_{-2}^{t} x(t-\tau)h(\tau)d\tau \\
&= \int_{-2}^{0} (1)(2+\tau) d\tau + \int_{0}^{2}(2)(2) d\tau \\
&= (2 \tau + \frac{\tau^2}{2}) \biggr\rvert_{-2}^{0} + 2 \tau \biggr\rvert_{0}^{2} \\
&= 6 , \text{ t > 2} 
\end{align}
$$

```{julia}
#| label: fig-graph-convolution-ex-1-gt-2
#| fig-cap: t > 2
t = 2.5

plot(x_shift,-3,3,label=L"x(t - \tau)")
plot!(h,-3,3,label=L"h(\tau)")
title!( "convolution x(t)*h(t), t > 2")
```

Combining the results, we obtain, see  @fig-graph-convolution-ex-1-result

$$
y(t) = \begin{cases}
   0.5t^2 + 2t + 2,  &\text{-2 < t < 0} \\
   2t+2,  &\text{0 < t < 2} \\
   6, &\text{ t > 2} \\
   0, &\text{otherwise} 
\end{cases}
$$ 

```{julia}
#| label: fig-graph-convolution-ex-1-result
#| fig-cap: convolution result 

y(t) = begin 
   if (-2 <= t) && (t <= 0)
      0.5*t*t + 2*t + 2 
   elseif (0 <= t) && (t <= 2)
      2*t + 2 
   elseif t > 2 
      6 
   else
      0  
   end    
end 

plot(y,-4,4)
title!( "convolution x(t)*h(t), result")
```

## 2.5 Block Diagram Representation 

The commutative property of the convolution integral. 
```{mermaid}
flowchart LR 
subgraph g1[1]
    direction LR    
    x["x(t)" ]-->h["h(t)" ]-->y["y(t)"];
    style x stroke-width:0px
    style y stroke-width:0px
end 

subgraph g2[2]
    direction LR 
    h1["h(t)" ]-->x1["x(t)" ]-->y1["y(t)"];
    style h1 stroke-width:0px
    style y1 stroke-width:0px
end 

g1-.-|equals|g2
```


The associative property of the convolution integral. 
```{mermaid}
flowchart LR 
subgraph g1[1]
    direction LR    
    x["x(t)" ]-->h1["h1(t)" ]-->h2["h2(t)" ]-->y["y(t)"];
    style x stroke-width:0px
    style y stroke-width:0px
end 

subgraph g2[2]
    direction LR 
    xx["x(t)" ]-->convolution["h1(t)*h2(t)" ]-->yy["y(t)"];
    style xx stroke-width:0px
    style yy stroke-width:0px
end 

g1-.-|equals|g2
```


The distributive property of the convolution integral. 
```{mermaid}
flowchart LR 
subgraph g1[1]
    direction LR    
    x["x(t)"]-->h1["h1(t)"] & h2["h2(t)"] 
    h1-->y["y(t)"] 
    h2-->y 
    style x stroke-width:0px
    style y stroke-width:0px
end 

subgraph g2[2]
    direction LR 
    xx["x(t)" ]-->addition["h1(t)+h2(t)" ]-->yy["y(t)"];
    style xx stroke-width:0px
    style yy stroke-width:0px
end 

g1-.-|equals|g2
```